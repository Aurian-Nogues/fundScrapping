{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define useful function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser13F(folder):\n",
    "    #will scan a fund folder and return all parsed info from 13-f in a da\n",
    "    lst_13F = list()\n",
    "    cols_names=['sub_rpt_dt','cusip','s_name','value','nshares','sub_rpttyp','sub_fil_dt']\n",
    "    tab_13F = pd.DataFrame(columns=cols_names)\n",
    "    n=0\n",
    "    with os.scandir(folder) as entries:\n",
    "        for file in entries:\n",
    "            fh = open(file)\n",
    "            Fname=file.name\n",
    "            #print(Fname)\n",
    "            n=0\n",
    "            i0=0\n",
    "            i1=1e6\n",
    "            report_CAT= None\n",
    "            for line in fh:\n",
    "                n=n+1\n",
    "                if line.find('CONFORMED PERIOD OF REPORT')>-1:\n",
    "                    sub_rpt_dt = datetime.strptime(str(int(line.split(sep=\":\")[1])), '%Y%m%d').strftime('%d/%m/%Y')\n",
    "                if line.find('FILED AS OF DATE')>-1:\n",
    "                    sub_fil_dt = datetime.strptime(str(int(line.split(sep=\":\")[1])), '%Y%m%d').strftime('%d/%m/%Y')\n",
    "                    sub_fil_dt = str(int(line.split(sep=\":\")[1]))\n",
    "                if line.find('CONFORMED SUBMISSION TYPE')>-1:\n",
    "                    sub_rpttyp = str(re.sub('\\n','',re.sub('\\t','',line.split(sep=\":\")[1])))\n",
    "                if line.find('FILENAME')>-1:\n",
    "                    report_CAT = str(re.sub('\\n','',line.split(sep=\">\")[1].split(sep=\"<\")[0]))[-3:]\n",
    "                    #print(Fname+' > input typ:'+report_CAT)\n",
    "                if len(line)<5 or report_CAT is None:\n",
    "                    continue\n",
    "                if report_CAT=='xml':      \n",
    "                    line_words = line.split(sep=\">\")\n",
    "                    if line.find('nameOfIssuer>')>-1:\n",
    "                        s_name = line_words[1].split(sep=\"<\")[0]\n",
    "                    if line.find('cusip>')>-1:\n",
    "                        cusip = line_words[1].split(sep=\"<\")[0]\n",
    "                    if line.find('value>')>-1:\n",
    "                        value = line_words[1].split(sep=\"<\")[0]\n",
    "                    if line.find('sshPrnamt>')>-1:\n",
    "                        nshares = float(line_words[1].split(sep=\"<\")[0])\n",
    "                        infoT=[[sub_rpt_dt,cusip,s_name,value,nshares,sub_rpttyp,sub_fil_dt]]\n",
    "                        lst_13F.append(infoT)\n",
    "                        infoT2 = pd.DataFrame(infoT,columns=cols_names)\n",
    "                        tab_13F = tab_13F.append(infoT2,ignore_index=True)\n",
    "                elif report_CAT=='txt':            \n",
    "    #                if line.find('CAPTION')>-1:\n",
    "    ##                    n=0\n",
    "                    if line.find('<S>')>-1:\n",
    "                        i0 = n\n",
    "                        lC = [m.start() for m in re.finditer('<C>', line)]\n",
    "                    if line.find('/TABLE')>-1:\n",
    "                        i1=n\n",
    "                        break\n",
    "    #                    print('i1',n)\n",
    "    #                print(n)\n",
    "                    if n>i0 and i0>0 and n<i1:\n",
    "                        line_words2 = list()\n",
    "                        for i in range(len([x for x in lC if x<len(line)])+1):\n",
    "                            if i==0:\n",
    "                                line_words2.append(line[:lC[i]].strip())\n",
    "                            elif i==len(lC)+1:\n",
    "                                line_words2.append(line[lC[i]:].strip())\n",
    "                            else:\n",
    "                                line_words2.append(line[lC[i-1]:lC[i]].strip())\n",
    "                        if line_words2==['No Reportable Holdings']:\n",
    "\n",
    "                            #print(Fname+': No Reportable Holdings!!!!')\n",
    "                            continue\n",
    "                        else:\n",
    "                            s_name = line_words2[0]\n",
    "                            cusip = str(line_words2[2])\n",
    "                            value = float(re.sub(',','',line_words2[3]))\n",
    "                            nshares = float(re.sub(',','',line_words2[4]))\n",
    "                            infoT=[[sub_rpt_dt,cusip,s_name,value,nshares,sub_rpttyp,sub_fil_dt]]\n",
    "                            lst_13F.append(infoT)\n",
    "                            infoT2 = pd.DataFrame(infoT,columns=cols_names)\n",
    "                            tab_13F = tab_13F.append(infoT2,ignore_index=True)\n",
    "    return(tab_13F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update all funds holdings csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of all funds\n",
    "fundsFolderPath = os.path.abspath(os.path.join('..','Data'))\n",
    "fundsList = os.listdir(fundsFolderPath)\n",
    "fundsList.remove('.gitignore') #remove giti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for each fund parse info and update fund csv\n",
    "for fund in fundsList:\n",
    "    #get fund id which is folder name in sec_edgar_filings\n",
    "    tempPath = os.path.abspath(os.path.join('..','Data',fund,'sec_edgar_filings'))\n",
    "    fundId = os.listdir(tempPath)[0]\n",
    "    #get list of all available filings files for that fund\n",
    "    fundPath = os.path.abspath(os.path.join('..','Data',fund,'sec_edgar_filings',fundId,'13F-HR'))\n",
    "    fundHoldingsDf = parser13F(fundPath) #returns a dataframe with fund holdings parsed from all files\n",
    "    #overwrite csv with new info\n",
    "    fundHoldingsFilePath = os.path.abspath(os.path.join('..','Data',fund,fund +'.csv'))\n",
    "    existingDatadf = pd.read_csv(fundHoldingsFilePath)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
